{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qPia4bmdOhs5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import KNNImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n"
      ],
      "metadata": {
        "id": "MS5VGqCAPbNC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
        "data['bmi'] = imputer.fit_transform(data[['bmi']])\n",
        "data.drop(data[data.gender == 'Other'].index, inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data.gender = data.gender.map({'Male': 0, 'Female': 1})\n",
        "data.ever_married = data.ever_married.map({'No': 0, 'Yes': 1})\n",
        "data.work_type = data.work_type.map({'Private': 0, 'Self-employed': 1, 'children': 2, 'Govt_job': 3, 'Never_worked': 4})\n",
        "data.Residence_type = data.Residence_type.map({'Urban': 0, 'Rural': 1})\n",
        "data.smoking_status = data.smoking_status.map({'never smoked': 0, 'formerly smoked': 1, 'smokes': 2, 'Unknown': 3})\n",
        "numeric_features = ['age', 'avg_glucose_level', 'bmi']\n",
        "scaler = StandardScaler()\n",
        "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n"
      ],
      "metadata": {
        "id": "XzArdvD8Pc-a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropped the 'id' column and separate features from target\n",
        "data = data.drop('id', axis=1)\n",
        "X = data.drop('stroke', axis=1)\n",
        "y = data['stroke']"
      ],
      "metadata": {
        "id": "Bx5_3C2gPenK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling and Polynomial Features\n",
        "numeric_features = ['age', 'avg_glucose_level', 'bmi']\n",
        "scaler = StandardScaler()\n",
        "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
      ],
      "metadata": {
        "id": "pzJ7t0WEIHOf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate polynomial features for the numeric columns\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(data[numeric_features])\n",
        "poly_columns = poly.get_feature_names_out(numeric_features)\n",
        "X_poly_df = pd.DataFrame(X_poly, columns=poly_columns)\n",
        "\n",
        "# Combine polynomial features back into the dataset\n",
        "data = data.drop(numeric_features, axis=1)\n",
        "data = pd.concat([data, X_poly_df], axis=1)"
      ],
      "metadata": {
        "id": "Q3nWK-ugIKaj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample minority class using SMOTE\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
      ],
      "metadata": {
        "id": "5I6RqOkdPgKJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use StratifiedKFold to maintain class proportions\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "l31_q5z7Pj47"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialized lists to store accuracy scores\n",
        "knn_scores = []\n",
        "rf_scores = []\n",
        "gbc_scores = []\n",
        "combined_scores = []"
      ],
      "metadata": {
        "id": "DKszbaDbPl0a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialized models\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "rf = RandomForestClassifier(n_estimators=200,max_depth=10, min_samples_split=2, random_state=42)\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n"
      ],
      "metadata": {
        "id": "_7q5y15kMqm1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performed cross-validation manually to average predictions for the combined model\n",
        "for train_index, test_index in skf.split(X_resampled, y_resampled):\n",
        "    X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
        "    y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
        "\n",
        "\n",
        "    # Train both models\n",
        "    knn.fit(X_train, y_train)\n",
        "    rf.fit(X_train, y_train)\n",
        "    gbc.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_knn = knn.predict(X_test)\n",
        "    y_pred_rf = rf.predict(X_test)\n",
        "    y_pred_gbc = gbc.predict(X_test)\n",
        "\n",
        "\n",
        "    # Combine predictions by averaging and rounding to the nearest integer\n",
        "    combined_predictions = np.round((y_pred_knn + y_pred_rf) / 2).astype(int)\n",
        "\n",
        "    # Calculate accuracy for each model\n",
        "    knn_scores.append(accuracy_score(y_test, y_pred_knn))\n",
        "    rf_scores.append(accuracy_score(y_test, y_pred_rf))\n",
        "    gbc_scores.append(accuracy_score(y_test, y_pred_gbc))\n",
        "\n",
        "    combined_scores.append(accuracy_score(y_test, combined_predictions))"
      ],
      "metadata": {
        "id": "ej6cQJdJPnsR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display cross-validated accuracy scores\n",
        "print(f\"KNN average accuracy: {np.mean(knn_scores)*100:.4f}\")\n",
        "print(f\"Random Forest average accuracy: {np.mean(rf_scores)*100:.4f}\")\n",
        "print(f\"Gradient Boosting average accuracy: {np.mean(gbc_scores)*100:.4f}\")\n",
        "print(f\"Combined Model (KNN + RF) average accuracy: {np.mean(combined_scores)*100:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mddr6fN5PppB",
        "outputId": "3f9f47cd-ffb2-40c8-9a4c-785f39908e69"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN average accuracy: 89.6296\n",
            "Random Forest average accuracy: 89.2490\n",
            "Gradient Boosting average accuracy: 84.5165\n",
            "Combined Model (KNN + RF) average accuracy: 91.6975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average accuracies for each model\n",
        "avg_accuracy_combined = np.mean(combined_scores)\n",
        "avg_accuracy_gbc = np.mean(gbc_scores)\n",
        "avg_accuracy_knn = np.mean(knn_scores)\n",
        "avg_accuracy_rf = np.mean(rf_scores)\n",
        "\n",
        "# Calculate variances (differences) between the combined model and each individual model\n",
        "variance_combined_vs_gbc = avg_accuracy_combined - avg_accuracy_gbc\n",
        "variance_combined_vs_knn = avg_accuracy_combined - avg_accuracy_knn\n",
        "variance_combined_vs_rf = avg_accuracy_combined - avg_accuracy_rf\n",
        "\n",
        "# Print the average accuracy scores\n",
        "print(f\"Accuracy score using Combined Model (KNN + RF): {avg_accuracy_combined * 100:.4f}%\")\n",
        "print(f\"Accuracy score using Gradient Boosting: {avg_accuracy_gbc * 100:.4f}%\")\n",
        "print(f\"Accuracy score using KNN: {avg_accuracy_knn * 100:.4f}%\")\n",
        "print(f\"Accuracy score using Random Forest: {avg_accuracy_rf * 100:.4f}%\")\n",
        "\n",
        "# Print the accuracy variances\n",
        "print(f\"Variance between Combined Model (KNN + RF) and KNN: {variance_combined_vs_knn * 100:.4f}%\")\n",
        "print(f\"Variance between Combined Model (KNN + RF) and Random Forest: {variance_combined_vs_rf * 100:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cs7LhWRTEi2",
        "outputId": "cfabc822-cfe8-4717-cae5-36d096738c77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score using Combined Model (KNN + RF): 91.6975%\n",
            "Accuracy score using Gradient Boosting: 84.5165%\n",
            "Accuracy score using KNN: 89.6296%\n",
            "Accuracy score using Random Forest: 89.2490%\n",
            "Variance between Combined Model (KNN + RF) and KNN: 2.0679%\n",
            "Variance between Combined Model (KNN + RF) and Random Forest: 2.4486%\n"
          ]
        }
      ]
    }
  ]
}